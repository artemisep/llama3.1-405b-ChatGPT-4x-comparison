{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162c07de-3450-4519-ba34-4c9bbcd87b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bd8913-9ea0-4407-9332-bb24f3fab39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_contents = [\n",
    "    \"Which one is bigger? 3.9 or 3.11\",\n",
    "    \"list top mechanistic interpretability papers\",\n",
    "    \"list top papers in llm mechanistic interpretability\",\n",
    "    \"you are an expert in llm mechanistic interpretability, explain in plain english what is mechanistic interpretability\",\n",
    "    \"you are an expert in the research of llm mechanistic interpretability, how do you utilize residual stream for research in mechanistic interpretability \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb41e397-7933-4739-8890-bba649eb73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c61647-5791-4692-a2ea-a9a4537246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"https://llama3-405b-hackathon.lepton.run/api/v1/\",\n",
    "    # Get your token from lepton.ai under Settings -> Tokens -> Workspace Token\n",
    "    api_key=os.environ['LEPTON_API_TOKEN']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38ce277-d19a-43f1-a32e-340399d168bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an expert in LLM (Large Language Model) mechanistic interpretability, I'd be delighted to share how I utilize residual streams for research in this area.\n",
      "\n",
      "**Background**\n",
      "\n",
      "Mechanistic interpretability aims to understand how complex models like LLMs work by identifying the underlying mechanisms and components that contribute to their behavior. Residual streams, a concept introduced in the Transformer architecture, have been instrumental in advancing our understanding of these models.\n",
      "\n",
      "**What are residual streams?**\n",
      "\n",
      "In the Transformer architecture, residual streams refer to the concatenation of the input embeddings with the output of each encoder layer. This allows the model to preserve the original input information while incorporating the learned representations from each layer. The residual stream is computed as:\n",
      "\n",
      "`residual_stream = input_embeddings + layer_output`\n",
      "\n",
      "**Utilizing residual streams for mechanistic interpretability**\n",
      "\n",
      "To utilize residual streams for mechanistic interpretability research, I employ the following methods:\n",
      "\n",
      "1. **Layer-wise analysis**: By examining the residual stream at each layer, I can identify how the model's representations evolve throughout the network. This helps to pinpoint the specific layers and components responsible for particular linguistic phenomena or behaviors.\n",
      "2. **Feature importance**: By analyzing the residual stream, I can determine the importance of individual input features (e.g., specific words or tokens) on the model's predictions. This is achieved by measuring the magnitude of the residual stream's values corresponding to each input feature.\n",
      "3. **Path attribution**: I use the residual stream to attribute the model's predictions to specific paths or sequences of computations within the network. This involves analyzing how the residual stream changes as the input propagates through the model, allowing me to identify the most influential components.\n",
      "4. **Hidden state analysis**: By examining the residual stream in conjunction with the hidden states of the model, I can gain insights into how the model's internal representations are transformed and updated during processing.\n",
      "5. **Ablation studies**: I perform ablation studies by selectively removing or modifying components of the residual stream to assess their impact on the model's behavior. This helps to identify the essential components and mechanisms contributing to specific phenomena.\n",
      "6. **Comparative analysis**: I compare the residual streams of different models or model variants to identify similarities and differences in their mechanisms and representations. This facilitates the transfer of insights and knowledge between models.\n",
      "\n",
      "**Tools and techniques**\n",
      "\n",
      "To facilitate the analysis of residual streams, I employ a range of tools and techniques, including:\n",
      "\n",
      "1. **Tensor decomposition**: I use tensor decomposition methods (e.g., PCA, t-SNE) to reduce the dimensionality of the residual stream and identify patterns and structures.\n",
      "2. **Visualization**: I utilize visualization tools (e.g., heatmaps, scatter plots) to represent the residual stream and its transformations throughout the model.\n",
      "3. **Clustering**: I apply clustering algorithms to group similar components or patterns in the residual stream, facilitating the identification of common mechanisms.\n",
      "4. **Correlation analysis**: I perform correlation analysis to examine the relationships between the residual stream and other model components or outputs.\n",
      "\n",
      "By leveraging residual streams and these analysis techniques, I can gain a deeper understanding of the complex mechanisms underlying LLMs and shed light on the intricate processes that govern their behavior."
     ]
    }
   ],
   "source": [
    "ind = 4\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3-405b\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_contents[ind]},\n",
    "    ],\n",
    "    max_tokens=1280,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if not chunk.choices:\n",
    "        continue\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content:\n",
    "        print(content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02492a4-f658-4a19-91ad-c824c3043723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_llamaInd_chat_py3.10.12",
   "language": "python",
   "name": "st_llamaind_chat_py3.10.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
